{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import ImageDataset\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        # for i, im in enumerate(x[0], 1):\n",
    "        #     plt.imsave(f\"./srcnn_layers/l1/{i}.png\", np.array(tensor_to_image(im.cpu())), cmap='gray', pil_kwargs={'compress_level':0})\n",
    "        x = self.relu(self.conv2(x))\n",
    "        # for i, im in enumerate(x[0], 1):\n",
    "        #     plt.imsave(f\"./srcnn_layers/l2/{i}.png\", np.array(tensor_to_image(im.cpu())), cmap='gray', pil_kwargs={'compress_level':0})\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "    \n",
    "    def process_image(self, lr_tensor):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            hr_tensor = self(lr_tensor.unsqueeze(0).to(device)).squeeze().cpu()\n",
    "        return hr_tensor\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"SRCNN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model, \n",
    "        train_dataloader, \n",
    "        eval_dataloader, \n",
    "        criterion, \n",
    "        optimizer, \n",
    "        trained_path, \n",
    "        start_epoch=1, \n",
    "        end_epoch=50, \n",
    "        device='cpu',\n",
    "        rgb=False):\n",
    "    \n",
    "    tqdmEpoch = start_epoch\n",
    "\n",
    "    num_epochs = end_epoch-start_epoch+1\n",
    "    \n",
    "    best_psnr = -float('inf')\n",
    "    best_ssim = -float('inf')\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_epoch = -1\n",
    "\n",
    "    with tqdm(total=len(train_dataloader) * num_epochs, desc=f'Epoch {tqdmEpoch}/{end_epoch}', unit=' patches') as pbar:\n",
    "        for epoch in range(start_epoch, end_epoch + 1):\n",
    "            #eval\n",
    "            avg_psnr, avg_ssim = eval(model, eval_dataloader, device, rgb=rgb)\n",
    "            if avg_psnr > best_psnr and avg_ssim > best_ssim:\n",
    "                best_psnr = avg_psnr\n",
    "                best_ssim = avg_ssim\n",
    "                best_epoch = tqdmEpoch-1\n",
    "                best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            pbar.set_description_str(f'Epoch {tqdmEpoch}/{end_epoch} | PSNR: {avg_psnr} | SSIM: {avg_ssim}', refresh=True)\n",
    "            \n",
    "            #train\n",
    "            avg_loss = train(model, train_dataloader, optimizer, criterion, pbar, device)\n",
    "\n",
    "            tqdmEpoch += 1\n",
    "            pbar.set_postfix(loss=avg_loss)\n",
    "\n",
    "            if epoch % 50 == 0:\n",
    "                save(model.state_dict(), model.get_name(), epoch, trained_path)\n",
    "\n",
    "        # final eval\n",
    "        avg_psnr, avg_ssim = eval(model, eval_dataloader, device, rgb=rgb)\n",
    "        if avg_psnr > best_psnr and avg_ssim > best_ssim:\n",
    "            best_epoch = tqdmEpoch-1\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        pbar.set_description_str(f'Epoch {tqdmEpoch-1}/{end_epoch} | PSNR: {avg_psnr} | SSIM: {avg_ssim}', refresh=True)\n",
    "\n",
    "    save(best_weights, model.get_name(), best_epoch, trained_path, best=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showcase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "start_epoch = 1 # 21884/epoch\n",
    "end_epoch = 200\n",
    "upscale_factor = 3\n",
    "metrics_rgb = False # Evaluate psnr and ssim on rgb channels or Y channel\n",
    "\n",
    "train_path = \"./Datasets/T91\"\n",
    "eval_path = \"./Datasets/Set5\"\n",
    "\n",
    "set5_path = \"./Datasets/Set5\"\n",
    "set14_path = \"./Datasets/Set14\"\n",
    "urban100_path = \"./Datasets/urban100\"\n",
    "bsd100_path = \"./Datasets/BSD100\"\n",
    "manga109_path = \"./Datasets/manga109\"\n",
    "\n",
    "mode = \"load\"\n",
    "# mode =  \"train\"\n",
    "# mode = \"load-train\"\n",
    "\n",
    "trained_path = \"TrainedModels/srcnn/X\" + str(upscale_factor) + \"/\"\n",
    "\n",
    "pretrained = [\"srcnn_best_175.pt\", \"srcnn_best_156_bs4.pt\", \"srcnn_best_185.pt\"] # x2 / x3 / x4\n",
    "load_model_name = pretrained[upscale_factor-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(train_path, upscale_factor, train=True, bic_up=True)\n",
    "eval_dataset = ImageDataset(eval_path, upscale_factor, train=False, bic_up=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRCNN().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.conv1.parameters(), 'lr': learning_rate},\n",
    "    {'params': model.conv2.parameters(), 'lr': learning_rate},\n",
    "    {'params': model.conv3.parameters(), 'lr': learning_rate * 0.1}\n",
    "])\n",
    "\n",
    "if mode == \"train\":\n",
    "    train_model(model, train_dataloader, eval_dataloader, criterion, optimizer, trained_path, start_epoch, end_epoch, device, metrics_rgb)\n",
    "elif mode == \"load-train\":\n",
    "    model.load_state_dict(torch.load(trained_path + load_model_name, weights_only=False))\n",
    "    print(\"Loaded model: \" + load_model_name)\n",
    "    train_model(model, train_dataloader, eval_dataloader, criterion, optimizer, trained_path, start_epoch, end_epoch, device, metrics_rgb)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(trained_path + load_model_name, weights_only=False))\n",
    "    print(\"Loaded model: \" + load_model_name)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set5_dataset = ImageDataset(set5_path, upscale_factor=upscale_factor, bic_up=True)\n",
    "set14_dataset = ImageDataset(set14_path, upscale_factor=upscale_factor, bic_up=True)\n",
    "# bsd100_dataset = ImageDataset(bsd100_path, upscale_factor=upscale_factor, bic_up=True)\n",
    "# urban100_dataset = ImageDataset(urban100_path, upscale_factor=upscale_factor, bic_up=True)\n",
    "# manga109_dataset = ImageDataset(manga109_path, upscale_factor=upscale_factor, bic_up=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_comparison_picture(model, set5_dataset, 2, (50, 50), scale=upscale_factor, other_model=False, rgb=metrics_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model:\", load_model_name)\n",
    "bic_psnr, bic_ssim, up_psnr, up_ssim = get_avg_metrics(model, set5_dataset, upscale_factor, rgb=metrics_rgb)\n",
    "print(\"Set5\\n\", f\"Bicubic / {round(bic_psnr, 4)} / {round(bic_ssim, 4)}\\n\", f\"SRCNN / {round(up_psnr, 4)} / {round(up_ssim, 4)}\")\n",
    "\n",
    "bic_psnr, bic_ssim, up_psnr, up_ssim = get_avg_metrics(model, set14_dataset, upscale_factor, rgb=metrics_rgb)\n",
    "print(\"Set14\\n\", f\"Bicubic / {round(bic_psnr, 4)} / {round(bic_ssim, 4)}\\n\", f\"SRCNN / {round(up_psnr, 4)} / {round(up_ssim, 4)}\")\n",
    "\n",
    "# bic_psnr, bic_ssim, up_psnr, up_ssim = get_avg_metrics(model, bsd100_dataset, upscale_factor, rgb=metrics_rgb)\n",
    "# print(\"BDS100\\n\", f\"Bicubic / {round(bic_psnr, 4)} / {round(bic_ssim, 4)}\\n\", f\"SRCNN / {round(up_psnr, 4)} / {round(up_ssim, 4)}\")\n",
    "\n",
    "# bic_psnr, bic_ssim, up_psnr, up_ssim = get_avg_metrics(model, urban100_dataset, upscale_factor, rgb=metrics_rgb)\n",
    "# print(\"urban100\\n\", f\"Bicubic / {round(bic_psnr, 4)} / {round(bic_ssim, 4)}\\n\", f\"SRCNN / {round(up_psnr, 4)} / {round(up_ssim, 4)}\")\n",
    "\n",
    "# bic_psnr, bic_ssim, up_psnr, up_ssim = get_avg_metrics(model, manga109_dataset, upscale_factor, rgb=metrics_rgb)\n",
    "# print(\"manga109\\n\", f\"Bicubic / {round(bic_psnr, 4)} / {round(bic_ssim, 4)}\\n\", f\"SRCNN / {round(up_psnr, 4)} / {round(up_ssim, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Set5\"\n",
    "# dataset_name = \"Set14\"\n",
    "# dataset_name = \"BSD100\"\n",
    "# dataset_name = \"urban100\"\n",
    "# dataset_name = \"manga109\"\n",
    "\n",
    "gt_path = f\"./Datasets/{dataset_name}/{dataset_name}_HR\"\n",
    "up_path_srcnn = f\"./Results/{dataset_name}/SRCNN/X{str(upscale_factor)}\"\n",
    "up_path_esrt = f\"./Results/{dataset_name}/ESRT/X{str(upscale_factor)}\"\n",
    "up_path_esrt_paper = f\"./Results/{dataset_name}/ESRT_paper/X{str(upscale_factor)}\"\n",
    "\n",
    "print(f\"{dataset_name} x{upscale_factor} results for:\")\n",
    "print(\"SRCNN\")\n",
    "metrics_from_results(gt_path, up_path_srcnn, metrics_rgb)\n",
    "print(\"ESRT\")\n",
    "metrics_from_results(gt_path, up_path_esrt, metrics_rgb)\n",
    "print(\"ESRT paper\")\n",
    "metrics_from_results(gt_path, up_path_esrt_paper, metrics_rgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
