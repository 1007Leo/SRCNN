{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import Div2kDataset, ImageDataset\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARN-M modules\n",
    "\n",
    "class ResidualEBlock(nn.Module):\n",
    "    def __init__(self, channels, groups=4):\n",
    "        super(ResidualEBlock, self).__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, padding=1, groups=groups),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1, groups=groups),\n",
    "            nn.Conv2d(channels, channels, 1),\n",
    "        )\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = torch.add(out, x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class RecursiveBlock(nn.Module):\n",
    "    def __init__(self, channels, num_blocks=3):\n",
    "        super(RecursiveBlock, self).__init__()\n",
    "        self.num_blocks = num_blocks\n",
    "        self.rec_b = ResidualEBlock(channels)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(channels * (i + 2), channels, 1),\n",
    "                nn.ReLU(True)\n",
    "            ) for i in range(num_blocks)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        current = x\n",
    "        \n",
    "        for i in range(self.num_blocks):\n",
    "            rec_b_out = self.rec_b(current)\n",
    "            concat = torch.cat(features + [rec_b_out], 1)\n",
    "            current = self.convs[i](concat)\n",
    "            features.append(rec_b_out)\n",
    "            \n",
    "        return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "        )\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = torch.add(out, x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class CascadingBlock(nn.Module):\n",
    "    def __init__(self, channels, num_blocks=3):\n",
    "        super(CascadingBlock, self).__init__()\n",
    "\n",
    "        self.body = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                ResidualBlock(channels),\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(channels * (i + 2), channels, 1),\n",
    "                    nn.ReLU(True)\n",
    "                )\n",
    "            ]) for i in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        res1 = self.body[0][0](x)\n",
    "        concat1 = torch.cat([res1, x], 1)\n",
    "        conv1 = self.body[0][1](concat1)\n",
    "\n",
    "        res2 = self.body[1][0](conv1)\n",
    "        concat2 = torch.cat([concat1, res2], 1)\n",
    "        conv2 = self.body[1][1](concat2)\n",
    "\n",
    "        res3 = self.body[2][0](conv2)\n",
    "        concat3 = torch.cat([concat2, res3], 1)\n",
    "        conv3 = self.body[2][1](concat3)\n",
    "\n",
    "        return conv3\n",
    "\n",
    "class Upsampler(nn.Sequential):\n",
    "    def __init__(self, scale, channels):\n",
    "        m = []\n",
    "        if (scale & (scale - 1)) == 0: # if scale == 2^n\n",
    "            for _ in range(int(math.log(scale, 2))):\n",
    "                m.append(nn.Conv2d(channels, 4*channels, 3, padding=1))\n",
    "                m.append(nn.PixelShuffle(2))\n",
    "        elif scale == 3:\n",
    "            m.append(nn.Conv2d(channels, 9*channels, 3, padding=1))\n",
    "            m.append(nn.PixelShuffle(3))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        super(Upsampler, self).__init__(*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CARN(nn.Module):\n",
    "    def __init__(self, scale=3, light=False):\n",
    "        super(CARN, self).__init__()\n",
    "        channels = 64\n",
    "        self.light = light\n",
    "\n",
    "        self.head = nn.Conv2d(3, channels, 3, padding=1)\n",
    "\n",
    "        num_blocks = 3\n",
    "        self.body = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                # CascadingBlock(channels),\n",
    "                RecursiveBlock(channels, 3) if light else CascadingBlock(channels),\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(channels * (i+2), channels, 1),\n",
    "                    nn.ReLU(True)\n",
    "                )\n",
    "            ]) for i in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "        self.upsampler = Upsampler(scale, channels)\n",
    "\n",
    "        self.tail = nn.Conv2d(channels, 3, 3, padding=1)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.head(x)\n",
    "\n",
    "        res1 = self.body[0][0](out)\n",
    "        concat1 = torch.cat([res1, out], 1)\n",
    "        conv1 = self.body[0][1](concat1)\n",
    "\n",
    "        res2 = self.body[1][0](conv1)\n",
    "        concat2 = torch.cat([concat1, res2], 1)\n",
    "        conv2 = self.body[1][1](concat2)\n",
    "\n",
    "        res3 = self.body[2][0](conv2)\n",
    "        concat3 = torch.cat([concat2, res3], 1)\n",
    "        conv3 = self.body[2][1](concat3)\n",
    "\n",
    "        out = self.upsampler(conv3)\n",
    "\n",
    "        out = self.tail(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def load_components(self, components, model_name):\n",
    "        pretrained = torch.load(model_name, weights_only=False)\n",
    "        state_dict = {}\n",
    "\n",
    "        for name, param in pretrained.items():\n",
    "            for component in components:\n",
    "                if component in name:\n",
    "                    state_dict[name] = param\n",
    "                    \n",
    "        self.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "\n",
    "    def process_image(self, lr_tensor):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            hr_tensor = self(lr_tensor.unsqueeze(0).to(device)).squeeze().cpu()\n",
    "        return hr_tensor\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"CARN-M\" if self.light else \"CARN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model, \n",
    "        train_dataloader, \n",
    "        eval_dataloader, \n",
    "        criterion, \n",
    "        optimizer, \n",
    "        learning_rate,\n",
    "        trained_path, \n",
    "        start_epoch=1, \n",
    "        end_epoch=50,\n",
    "        device='cpu',\n",
    "        rgb=False):\n",
    "    \n",
    "    tqdmEpoch = start_epoch\n",
    "\n",
    "    num_epochs = end_epoch-start_epoch+1\n",
    "    \n",
    "    best_psnr = -float('inf')\n",
    "    best_ssim = -float('inf')\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_epoch = -1\n",
    "\n",
    "    with tqdm(total=len(train_dataloader) * num_epochs, desc=f'Epoch {tqdmEpoch}/{end_epoch}', unit='patches') as pbar:\n",
    "        for epoch in range(start_epoch, end_epoch + 1):\n",
    "            # eval\n",
    "            avg_psnr, avg_ssim = eval(model, eval_dataloader, device, -1, rgb)\n",
    "            if avg_psnr > best_psnr and avg_ssim > best_ssim:\n",
    "                best_psnr = avg_psnr\n",
    "                best_ssim = avg_ssim\n",
    "                best_epoch = tqdmEpoch-1\n",
    "                best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            pbar.set_description_str(f'Epoch {tqdmEpoch}/{end_epoch} | PSNR: {avg_psnr} | SSIM: {avg_ssim}', refresh=True)\n",
    "\n",
    "            # decrease lr in half every 4*10^5 steps\n",
    "            cur_lr = optimizer.param_groups[0]['lr']\n",
    "            factor = len(train_dataloader) * num_epochs // 400000\n",
    "            lr = learning_rate * (0.5 ** factor)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            if cur_lr != lr:\n",
    "                print(f\"New learning rate {lr} at epoch {epoch}\")\n",
    "\n",
    "            # train\n",
    "            avg_loss = train(model, train_dataloader, optimizer, criterion, pbar, device)\n",
    "\n",
    "            tqdmEpoch += 1\n",
    "            pbar.set_postfix(loss=avg_loss)\n",
    "\n",
    "            if epoch % 5 == 0:\n",
    "                save(model.state_dict(), model.get_name(), epoch, trained_path)\n",
    "\n",
    "        # final eval\n",
    "        avg_psnr, avg_ssim = eval(model, eval_dataloader, device, -1, rgb)\n",
    "        if avg_psnr >= best_psnr and avg_ssim >= best_ssim:\n",
    "            best_epoch = tqdmEpoch-1\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        pbar.set_description_str(f'Epoch {tqdmEpoch-1}/{end_epoch} | PSNR: {avg_psnr} | SSIM: {avg_ssim}', refresh=True)\n",
    "\n",
    "    save(best_weights, model.get_name(), best_epoch, trained_path, best=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showcase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 2e-4\n",
    "start_epoch=47\n",
    "end_epoch=50\n",
    "upscale_factor = 3\n",
    "patch_size = 64 * upscale_factor\n",
    "num_workers = 16\n",
    "metrics_rgb = False # Evaluate psnr and ssim on rgb channels or Y channel\n",
    "carn_m = False\n",
    "\n",
    "train_path = \"./Datasets/DIV2K\"\n",
    "eval_path = \"./Datasets/Set5\"\n",
    "\n",
    "set5_path = \"./Datasets/Set5\"\n",
    "set14_path = \"./Datasets/Set14\"\n",
    "urban100_path = \"./Datasets/urban100\"\n",
    "bsd100_path = \"./Datasets/BSD100\"\n",
    "manga109_path = \"./Datasets/manga109\"\n",
    "\n",
    "mode = \"load\"\n",
    "# mode =  \"train\"\n",
    "# mode = \"load-train\"\n",
    "\n",
    "\"\"\"\n",
    "part_load: pretrained model path\n",
    "Loads all parameters except the upsampler\n",
    "Use this if you trained one scale and want to train others\n",
    "Works only in \"train\" mode\n",
    "\"\"\"\n",
    "# part_load = \"TrainedModels/carn/X3/carn_best_46.pt\"\n",
    "part_load = \"\"\n",
    "\n",
    "trained_path = \"TrainedModels/carn/X\" + str(upscale_factor) + \"/\"\n",
    "\n",
    "pretrained = [\"carn_best_9.pt\", \"carn_best_46.pt\", \"carn_best_13.pt\"] # x2 / x3 / x4\n",
    "load_model_name = pretrained[upscale_factor-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Div2kDataset(train_path, train=True, repeat=40, upscale_factor=upscale_factor, patch_size=patch_size)\n",
    "eval_dataset = ImageDataset(eval_path, upscale_factor=upscale_factor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, num_workers=num_workers, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CARN(upscale_factor, carn_m).to(device)\n",
    "criterion = nn.L1Loss().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_params = 0\n",
    "for param in model.parameters():\n",
    "    num_params += param.numel()\n",
    "print(f'Total number of parameters: {num_params}')\n",
    "\n",
    "\n",
    "if mode == \"train\":\n",
    "    if part_load != \"\":\n",
    "        model.load_components(['head', 'body', 'tail'], part_load)\n",
    "        print(f\"Loaded partial weights from {part_load}\")\n",
    "    train_model(model, train_dataloader, eval_dataloader, criterion, optimizer, learning_rate, trained_path, start_epoch, end_epoch, device, metrics_rgb)\n",
    "elif mode == \"load-train\":\n",
    "    model.load_state_dict(torch.load(trained_path + load_model_name, weights_only=False))\n",
    "    print(\"Loaded model: \" + load_model_name)\n",
    "    train_model(model, train_dataloader, eval_dataloader, criterion, optimizer, learning_rate, trained_path, start_epoch, end_epoch, device, metrics_rgb)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(trained_path + load_model_name, weights_only=False))\n",
    "    print(\"Loaded model: \" + load_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set5_dataset = ImageDataset(set5_path, upscale_factor=upscale_factor)\n",
    "set14_dataset = ImageDataset(set14_path, upscale_factor=upscale_factor)\n",
    "# bsd100_dataset = ImageDataset(bsd100_path, upscale_factor=upscale_factor)\n",
    "# urban100_dataset = ImageDataset(urban100_path, upscale_factor=upscale_factor)\n",
    "# manga109_dataset = ImageDataset(manga109_path, upscale_factor=upscale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_comparison_picture(model, set5_dataset, 2, (50, 50), scale=upscale_factor, other_model=\"ESRT\", rgb=metrics_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model:\", load_model_name)\n",
    "bic_psnr, bic_ssim, up_psnr, up_ssim = get_avg_metrics(model, set5_dataset, upscale_factor, rgb=metrics_rgb)\n",
    "print(\"Set5\\n\", f\"Bicubic / {bic_psnr} / {bic_ssim}\\n\", f\"CARN / {up_psnr} / {up_ssim}\")\n",
    "\n",
    "bic_psnr, bic_ssim, up_psnr, up_ssim = get_avg_metrics(model, set14_dataset, upscale_factor, rgb=metrics_rgb)\n",
    "print(\"Set14\\n\", f\"Bicubic / {bic_psnr} / {bic_ssim}\\n\", f\"CARN / {up_psnr} / {up_ssim}\")\n",
    "\n",
    "# bic_psnr, bic_ssim, up_psnr, up_ssim = get_avg_metrics(model, bsd100_dataset, upscale_factor, rgb=metrics_rgb)\n",
    "# print(\"BSD100\\n\", f\"Bicubic / {bic_psnr} / {bic_ssim}\\n\", f\"CARN / {up_psnr} / {up_ssim}\")\n",
    "\n",
    "# bic_psnr, bic_ssim, up_psnr, up_ssim = get_avg_metrics(model, urban100_dataset, upscale_factor, chop_size=25000, rgb=metrics_rgb)\n",
    "# print(\"urban100\\n\", f\"Bicubic / {bic_psnr} / {bic_ssim}\\n\", f\"CARN / {up_psnr} / {up_ssim}\")\n",
    "\n",
    "# bic_psnr, bic_ssim, up_psnr, up_ssim = get_avg_metrics(model, manga109_dataset, upscale_factor, chop_size=45000, rgb=metrics_rgb)\n",
    "# print(\"manga109\\n\", f\"Bicubic / {bic_psnr} / {bic_ssim}\\n\", f\"CARN / {up_psnr} / {up_ssim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"Set5\", \n",
    "    # \"Set14\", \n",
    "    # \"BSD100\", \n",
    "    # \"urban100\", \n",
    "    # \"manga109\"\n",
    "    ]\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    gt_path = f\"./Datasets/{dataset_name}/{dataset_name}_HR\"\n",
    "    up_path_srcnn = f\"./Results/{dataset_name}/SRCNN/X{str(upscale_factor)}\"\n",
    "    up_path_carn = f\"./Results/{dataset_name}/CARN/X{str(upscale_factor)}\"\n",
    "    up_path_esrt = f\"./Results/{dataset_name}/ESRT/X{str(upscale_factor)}\"\n",
    "    # up_path_esrt_paper = f\"./Results/{dataset_name}/ESRT_paper/X{str(upscale_factor)}\"\n",
    "\n",
    "    print(f\"{dataset_name} x{upscale_factor} results for:\")\n",
    "    print(\"SRCNN\")\n",
    "    metrics_from_results(gt_path, up_path_srcnn, metrics_rgb)\n",
    "    print(\"CARN\")\n",
    "    metrics_from_results(gt_path, up_path_carn, metrics_rgb)\n",
    "    print(\"ESRT\")\n",
    "    metrics_from_results(gt_path, up_path_esrt, metrics_rgb)\n",
    "    # print(\"ESRT paper\")\n",
    "    # metrics_from_results(gt_path, up_path_esrt_paper, metrics_rgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
